{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ee5bee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c642eff6954559a19a9ba9333d0120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e5e8d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7437411757184a5ca5a9b8dff6334149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac4131a34094706843eff970217a747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/5014 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\sabari\\AppData\\Local\\Temp\\ipykernel_124272\\1622170860.py:118: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10060' max='10060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10060/10060 54:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.715800</td>\n",
       "      <td>0.546511</td>\n",
       "      <td>0.840418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.396100</td>\n",
       "      <td>0.373409</td>\n",
       "      <td>0.874969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.297500</td>\n",
       "      <td>0.333395</td>\n",
       "      <td>0.889883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.228300</td>\n",
       "      <td>0.346098</td>\n",
       "      <td>0.886155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.154600</td>\n",
       "      <td>0.298600</td>\n",
       "      <td>0.904052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>0.303458</td>\n",
       "      <td>0.915237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.081200</td>\n",
       "      <td>0.325454</td>\n",
       "      <td>0.913249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>0.345408</td>\n",
       "      <td>0.917226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.353958</td>\n",
       "      <td>0.918966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.360124</td>\n",
       "      <td>0.918469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [252/252 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Final Accuracy: 91.90%\n",
      "âœ… Model saved to: ./vit-weed-pest-model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from datasets import load_dataset\n",
    "from transformers import ViTForImageClassification, TrainingArguments, Trainer\n",
    "from transformers import ViTImageProcessor\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# Configs\n",
    "DATASET_DIR = \"D:/project files/steve pest and weed detection/dataset\"\n",
    "MODEL_NAME = \"google/vit-base-patch16-224-in21k\"\n",
    "OUTPUT_DIR = \"./vit-weed-pest-model\"\n",
    "\n",
    "# Load dataset from folder using Hugging Face Datasets\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=DATASET_DIR)\n",
    "\n",
    "# Split into 80% train / 20% test\n",
    "split_dataset = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "train_ds = split_dataset[\"train\"]\n",
    "test_ds = split_dataset[\"test\"]\n",
    "\n",
    "# Extract label info\n",
    "labels = train_ds.features[\"label\"].names\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in id2label.items()}\n",
    "num_labels = len(labels)\n",
    "\n",
    "# Load Hugging Face ViT image processor\n",
    "image_processor = ViTImageProcessor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Define transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.GaussianBlur(kernel_size=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "])\n",
    "\n",
    "# Custom Dataset wrapper to apply transforms\n",
    "class HFDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, transform=None):\n",
    "        self.dataset = hf_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        image = item[\"image\"]  # PIL Image\n",
    "        label = item[\"label\"]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return {\"pixel_values\": image, \"label\": label}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "# Wrap datasets with transforms\n",
    "train_dataset = HFDataset(train_ds, transform=train_transforms)\n",
    "test_dataset = HFDataset(test_ds, transform=test_transforms)\n",
    "\n",
    "# Load ViT model\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# Load accuracy metric\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Metric computation\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return accuracy.compute(predictions=preds, references=labels)\n",
    "\n",
    "# Data collator\n",
    "def collate_fn(batch):\n",
    "    pixel_values = torch.stack([x[\"pixel_values\"] for x in batch])\n",
    "    labels = torch.tensor([x[\"label\"] for x in batch])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_total_limit=2,\n",
    "    \n",
    "    \n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collate_fn,\n",
    "    tokenizer=image_processor  # only used for logging; optional\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n",
    "\n",
    "# Final evaluation\n",
    "metrics = trainer.evaluate()\n",
    "print(f\"ðŸ“Š Final Accuracy: {metrics['eval_accuracy']*100:.2f}%\")\n",
    "\n",
    "# Save the final model\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "print(f\"âœ… Model saved to: {OUTPUT_DIR}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aae7a8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf1c5a3fae8f4b869d60ba42fbeaa3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sabari\\anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sabari\\.cache\\huggingface\\hub\\models--sabari15--ViT-base16-fine-tuned-crop-disease-model. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4300fd651a774f6faedb106638d49a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/343M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/sabari15/ViT-base16-fine-tuned-crop-disease-model/commit/d7c1bc128619b2eb73aa6bbf342ab580d0d8b185', commit_message='Upload ViTForImageClassification', commit_description='', oid='d7c1bc128619b2eb73aa6bbf342ab580d0d8b185', pr_url=None, repo_url=RepoUrl('https://huggingface.co/sabari15/ViT-base16-fine-tuned-crop-disease-model', endpoint='https://huggingface.co', repo_type='model', repo_id='sabari15/ViT-base16-fine-tuned-crop-disease-model'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"sabari15/ViT-base16-fine-tuned-crop-disease-model\", token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd258425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f91bcb6bef14d878416c565f07926ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4729a93b60414cfeb73e8b051b5d7691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/5014 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_path = \"D:/project files/steve pest and weed detection/dataset\"\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57c481fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'label' is the column with class indices\n",
    "labels = dataset['train']['label']\n",
    "unique_labels = np.unique(labels)\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd53e70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cashew anthracnose', 'Cashew gumosis', 'Cashew healthy', 'Cashew leaf miner', 'Cashew red rust', 'Cassava bacterial blight', 'Cassava brown spot', 'Cassava green mite', 'Cassava healthy', 'Cassava mosaic', 'Maize fall armyworm', 'Maize grasshoper', 'Maize healthy', 'Maize leaf beetle', 'Maize leaf blight', 'Maize leaf spot', 'Maize streak virus', 'Tomato healthy', 'Tomato leaf blight', 'Tomato leaf curl', 'Tomato septoria leaf spot', 'Tomato verticulium wilt']\n"
     ]
    }
   ],
   "source": [
    "label_names = dataset['train'].features['label'].names\n",
    "print(label_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
